{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Scenario 1: Image Creation on Web Gradio UI\n",
        "\n",
        "###Step 1: Setup Environment"
      ],
      "metadata": {
        "id": "VsC1Vaey56tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64"
      ],
      "metadata": {
        "id": "EVA5SP5E49u4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "tZU1h0Pt1Z0q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Define Image Generation Function"
      ],
      "metadata": {
        "id": "LVfrs91l6HYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client (reads OPENAI_API_KEY from env)\n",
        "client = OpenAI()\n",
        "\n",
        "def generate_image(text_prompt):\n",
        "    try:\n",
        "        result = client.images.generate(\n",
        "            model=\"gpt-image-1\",\n",
        "            prompt=text_prompt,\n",
        "            size=\"1024x1024\"\n",
        "        )\n",
        "\n",
        "        # Decode base64 image\n",
        "        img_base64 = result.data[0].b64_json\n",
        "        img_bytes = base64.b64decode(img_base64)\n",
        "\n",
        "        # Colab-safe PIL handling\n",
        "        with BytesIO(img_bytes) as bio:\n",
        "            img = Image.open(bio).convert(\"RGB\")\n",
        "            img = img.copy()\n",
        "\n",
        "        return img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", repr(e))\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "sN447kaH47om"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Create Gradio Interface"
      ],
      "metadata": {
        "id": "O7jqmGxZ6YQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=generate_image,\n",
        "    inputs=gr.Textbox(\n",
        "        label=\"Enter a text prompt\",\n",
        "        placeholder=\"Type a description...\"\n",
        "    ),\n",
        "    outputs=gr.Image(type=\"pil\"),\n",
        "    title=\"Image Generation from Text\",\n",
        "    description=\"Enter a text description to generate an image.\"\n",
        ")\n",
        "\n",
        "iface.launch(\n",
        "    debug=True,\n",
        "    share=True,\n",
        "    inline=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Ey9E5slO5EYP",
        "outputId": "77f074fd-a5c5-4503-c094-a5d2bf32127c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://991ad0903f9e60f54a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://991ad0903f9e60f54a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://991ad0903f9e60f54a.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Scenario 2: Logo Designing for a Fictional Company: LogoMaster"
      ],
      "metadata": {
        "id": "p_G_pO5y6m_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "# Initialize OpenAI client (reads API key from env)\n",
        "client = OpenAI()\n",
        "\n",
        "# Function to generate image based on text prompt and category\n",
        "def generate_image(text_prompt, category):\n",
        "    try:\n",
        "        # Build prompt based on category\n",
        "        if category == \"Logos\":\n",
        "            prompt_text = f\"Create a clean, modern logo for {text_prompt}\"\n",
        "        elif category == \"Company\":\n",
        "            prompt_text = f\"Generate a professional image representing the company {text_prompt}\"\n",
        "        else:\n",
        "            prompt_text = text_prompt\n",
        "\n",
        "        # Generate image\n",
        "        result = client.images.generate(\n",
        "            model=\"gpt-image-1\",\n",
        "            prompt=prompt_text,\n",
        "            size=\"1024x1024\"\n",
        "        )\n",
        "\n",
        "        # Decode base64 image\n",
        "        img_base64 = result.data[0].b64_json\n",
        "        img_bytes = base64.b64decode(img_base64)\n",
        "\n",
        "        with BytesIO(img_bytes) as bio:\n",
        "            img = Image.open(bio).convert(\"RGB\")\n",
        "            img = img.copy()\n",
        "\n",
        "        return img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", repr(e))\n",
        "        return None\n",
        "\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_image,\n",
        "    inputs=[\n",
        "        gr.Textbox(\n",
        "            label=\"Enter a description\",\n",
        "            placeholder=\"e.g. AI startup, coffee brand, fintech company\"\n",
        "        ),\n",
        "        gr.Radio(\n",
        "            choices=[\"Logos\", \"Company\"],\n",
        "            label=\"Select Category\",\n",
        "            value=\"Logos\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Image(type=\"pil\", label=\"Generated Image\"),\n",
        "    title=\"Image Generation from Text\",\n",
        "    description=\"Enter a description and select a category to generate an image.\"\n",
        ")\n",
        "\n",
        "# Launch\n",
        "iface.launch(\n",
        "    debug=True,\n",
        "    share=True,\n",
        "    inline=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "q1JQhZNR69-b",
        "outputId": "d22a7b5f-be67-4478-cb0a-fac8120edf37"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://65688410cd6349a7ae.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://65688410cd6349a7ae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://65688410cd6349a7ae.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}